{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12969895,"sourceType":"datasetVersion","datasetId":8208803}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U langchain --no-deps\n!pip install -U langchain-community --no-deps\n!pip install -U langchain-groq --no-deps\n!pip install -U langchain-chroma --no-deps\n!pip install -U langchain-openai --no-deps\n!pip install -U llama-index --no-deps\n\n# Extra runtime libraries (safe ones, no conflicts)\n!pip install -U faiss-cpu chromadb gradio sentence-transformers pypdf unstructured[all-docs] python-pptx openpyxl duckduckgo-search ddgs\n\n\n\n\nfrom kaggle_secrets import UserSecretsClient\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\n# load the Groq API key from Kaggle Secrets\nsecrets = UserSecretsClient()\nos.environ[\"GROQ_API_KEY\"] = secrets.get_secret(\"GROQ_API_KEY\")\nprint(\"Groq API key loaded âœ…\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-14T18:34:59.234387Z","iopub.execute_input":"2025-09-14T18:34:59.235189Z","iopub.status.idle":"2025-09-14T18:35:12.680177Z","shell.execute_reply.started":"2025-09-14T18:34:59.235151Z","shell.execute_reply":"2025-09-14T18:35:12.679283Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\nRequirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.29)\nRequirement already satisfied: langchain-groq in /usr/local/lib/python3.11/dist-packages (0.3.8)\nRequirement already satisfied: langchain-chroma in /usr/local/lib/python3.11/dist-packages (0.2.6)\nRequirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.33)\nRequirement already satisfied: llama-index in /usr/local/lib/python3.11/dist-packages (0.14.0)\nRequirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.12.0)\nRequirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (1.0.21)\nRequirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.45.0)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (5.1.0)\nRequirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (6.0.0)\nRequirement already satisfied: python-pptx in /usr/local/lib/python3.11/dist-packages (1.0.2)\nRequirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\nRequirement already satisfied: duckduckgo-search in /usr/local/lib/python3.11/dist-packages (8.1.1)\nRequirement already satisfied: ddgs in /usr/local/lib/python3.11/dist-packages (9.5.5)\nRequirement already satisfied: unstructured[all-docs] in /usr/local/lib/python3.11/dist-packages (0.18.14)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\nRequirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\nRequirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.11.7)\nRequirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.4.2)\nRequirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.3)\nRequirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.4.0)\nRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.14.0)\nRequirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.22.1)\nRequirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.37.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.37.0)\nRequirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.37.0)\nRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.2)\nRequirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\nRequirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\nRequirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\nRequirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\nRequirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.74.0)\nRequirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.3.0)\nRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.16.0)\nRequirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (33.1.0)\nRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (8.5.0)\nRequirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\nRequirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.2.0)\nRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.18)\nRequirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (14.0.0)\nRequirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.24.0)\nRequirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\nRequirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.1.0)\nRequirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.13)\nRequirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\nRequirement already satisfied: gradio-client==1.13.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.13.0)\nRequirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.4)\nRequirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\nRequirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.1.5)\nRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.3)\nRequirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.3.0)\nRequirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\nRequirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\nRequirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.0)\nRequirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\nRequirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\nRequirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\nRequirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.0)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.13.0->gradio) (2025.5.1)\nRequirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.13.0->gradio) (12.0)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.4)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\nRequirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (3.4.2)\nRequirement already satisfied: filetype in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (1.2.0)\nRequirement already satisfied: python-magic in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (0.4.27)\nRequirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (6.0.1)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (3.9.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (2.32.5)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (4.13.4)\nRequirement already satisfied: emoji in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (2.14.1)\nRequirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (0.6.7)\nRequirement already satisfied: python-iso639 in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (2025.2.18)\nRequirement already satisfied: langdetect in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (1.0.9)\nRequirement already satisfied: rapidfuzz in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (3.14.1)\nRequirement already satisfied: backoff in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (2.2.1)\nRequirement already satisfied: unstructured-client in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (0.42.3)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (1.17.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (7.0.0)\nRequirement already satisfied: python-oxmsg in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (0.0.2)\nRequirement already satisfied: html5lib in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (1.1)\nRequirement already satisfied: msoffcrypto-tool in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (5.4.2)\nRequirement already satisfied: xlrd in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (2.0.2)\nRequirement already satisfied: onnx>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (1.18.0)\nRequirement already satisfied: pdf2image in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (1.17.0)\nRequirement already satisfied: pi-heif in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (1.1.0)\nRequirement already satisfied: google-cloud-vision in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (3.10.2)\nRequirement already satisfied: python-docx>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (1.2.0)\nRequirement already satisfied: unstructured.pytesseract>=0.3.12 in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (0.3.15)\nRequirement already satisfied: pdfminer.six in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (20250506)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (3.5)\nRequirement already satisfied: pypandoc in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (1.15)\nRequirement already satisfied: effdet in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (0.4.1)\nRequirement already satisfied: unstructured-inference>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (1.0.5)\nRequirement already satisfied: pikepdf in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (9.11.0)\nRequirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (3.8.2)\nRequirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (3.2.8)\nRequirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\nRequirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (8.2.1)\nRequirement already satisfied: primp>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (0.15.0)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\nRequirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.6.15)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.18.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.5)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.25.1)\nRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\nRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\nRequirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.40.3)\nRequirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\nRequirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\nRequirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\nRequirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\nRequirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2.4.1)\nRequirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.17.0->unstructured[all-docs]) (6.32.1)\nRequirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\nRequirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\nRequirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\nRequirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.58b0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\nRequirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\nRequirement already satisfied: opencv-python!=4.7.0.68 in /usr/local/lib/python3.11/dist-packages (from unstructured-inference>=1.0.5->unstructured[all-docs]) (4.11.0.86)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from unstructured-inference>=1.0.5->unstructured[all-docs]) (3.7.2)\nRequirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from unstructured-inference>=1.0.5->unstructured[all-docs]) (1.0.15)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from unstructured-inference>=1.0.5->unstructured[all-docs]) (1.8.1)\nRequirement already satisfied: pypdfium2 in /usr/local/lib/python3.11/dist-packages (from unstructured-inference>=1.0.5->unstructured[all-docs]) (4.30.0)\nRequirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\nRequirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\nRequirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\nRequirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->unstructured[all-docs]) (2.7)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->unstructured[all-docs]) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->unstructured[all-docs]) (0.9.0)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from effdet->unstructured[all-docs]) (0.21.0+cu124)\nRequirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from effdet->unstructured[all-docs]) (2.0.10)\nRequirement already satisfied: omegaconf>=2.0 in /usr/local/lib/python3.11/dist-packages (from effdet->unstructured[all-docs]) (2.3.0)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[all-docs]) (2.25.1)\nRequirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-vision->unstructured[all-docs]) (1.26.1)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from html5lib->unstructured[all-docs]) (0.5.1)\nRequirement already satisfied: cryptography>=39.0 in /usr/local/lib/python3.11/dist-packages (from msoffcrypto-tool->unstructured[all-docs]) (44.0.3)\nRequirement already satisfied: olefile>=0.46 in /usr/local/lib/python3.11/dist-packages (from msoffcrypto-tool->unstructured[all-docs]) (0.47)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured[all-docs]) (1.5.1)\nRequirement already satisfied: Deprecated in /usr/local/lib/python3.11/dist-packages (from pikepdf->unstructured[all-docs]) (1.2.18)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured[all-docs]) (1.0.0)\nRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=39.0->msoffcrypto-tool->unstructured[all-docs]) (1.17.1)\nRequirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[all-docs]) (1.74.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\nRequirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf>=2.0->effdet->unstructured[all-docs]) (4.9.3)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured[all-docs]) (1.1.0)\nRequirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->unstructured-inference>=1.0.5->unstructured[all-docs]) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->unstructured-inference>=1.0.5->unstructured[all-docs]) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->unstructured-inference>=1.0.5->unstructured[all-docs]) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->unstructured-inference>=1.0.5->unstructured[all-docs]) (1.4.8)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->unstructured-inference>=1.0.5->unstructured[all-docs]) (3.0.9)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=39.0->msoffcrypto-tool->unstructured[all-docs]) (2.22)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\nGroq API key loaded âœ…\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"from __future__ import annotations\nimport os, re, json, ast\nfrom typing import TypedDict, List, Dict, Any, Optional","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T18:24:08.554309Z","iopub.execute_input":"2025-09-14T18:24:08.554552Z","iopub.status.idle":"2025-09-14T18:24:08.558679Z","shell.execute_reply.started":"2025-09-14T18:24:08.554527Z","shell.execute_reply":"2025-09-14T18:24:08.558066Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"# === Kaggle Secrets ===\ntry:\n    from kaggle_secrets import UserSecretsClient\n    secrets = UserSecretsClient()\n    os.environ[\"GROQ_API_KEY\"] = secrets.get_secret(\"GROQ_API_KEY\")\n    print(\"Groq API key loaded âœ…\")\nexcept Exception as e:\n    print(\"[WARN] Could not load GROQ_API_KEY from Kaggle Secrets:\", e)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T18:24:08.559556Z","iopub.execute_input":"2025-09-14T18:24:08.559844Z","iopub.status.idle":"2025-09-14T18:24:08.704283Z","shell.execute_reply.started":"2025-09-14T18:24:08.559827Z","shell.execute_reply":"2025-09-14T18:24:08.703572Z"}},"outputs":[{"name":"stdout","text":"Groq API key loaded âœ…\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"# === LangChain / LLM ===\nfrom langchain_groq import ChatGroq\nfrom langchain.schema import HumanMessage, SystemMessage, AIMessage\n\n\n# === Vector Memory ===\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\nfrom langchain_chroma import Chroma\n\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\n# === LangGraph ===\nfrom langgraph.graph import StateGraph, END\n\n\n# === Search ===  duck duck go search\nfrom ddgs import DDGS","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T18:24:08.705724Z","iopub.execute_input":"2025-09-14T18:24:08.706167Z","iopub.status.idle":"2025-09-14T18:24:08.710158Z","shell.execute_reply.started":"2025-09-14T18:24:08.706150Z","shell.execute_reply":"2025-09-14T18:24:08.709535Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# ------------------------\n# GLOBALS / CONFIG\n# ------------------------\nLLM_MODEL = os.environ.get(\"GROQ_MODEL\", \"qwen/qwen3-32b\")\nTEMPERATURE = float(os.environ.get(\"LLM_TEMPERATURE\", \"0\"))\nMAX_REFLECTIONS = int(os.environ.get(\"MAX_REFLECTIONS\", \"2\"))\nMEM_COLLECTION = os.environ.get(\"MEM_COLLECTION\", \"mini_manus_memory\")\nEMBED_MODEL = os.environ.get(\"EMBED_MODEL\", \"all-MiniLM-L6-v2\")\n\n\n# Persistent directory for Kaggle (working dir is saved in session)\nPERSIST_DIR = \"/kaggle/working/agent_memory\"\n\n\n# Initialize LLM (requires GROQ_API_KEY)\n_llm = ChatGroq(model=LLM_MODEL, temperature=TEMPERATURE)\n\n\n# Initialize vector memory\n_embedding_fn = HuggingFaceEmbeddings(model_name=EMBED_MODEL)\n_vectorstore = Chroma(\ncollection_name=MEM_COLLECTION,\nembedding_function=_embedding_fn,\npersist_directory=PERSIST_DIR\n)\n\n# âœ… DEFINE the variable, but leave it empty. We will create it in the loop.\n_vectorstore: Optional[Chroma] = None\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T18:24:08.710779Z","iopub.execute_input":"2025-09-14T18:24:08.710942Z","iopub.status.idle":"2025-09-14T18:24:10.098269Z","shell.execute_reply.started":"2025-09-14T18:24:08.710929Z","shell.execute_reply":"2025-09-14T18:24:10.097704Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"from langchain_community.document_loaders import (\n    TextLoader, PyPDFLoader, CSVLoader, UnstructuredExcelLoader,\n    UnstructuredPowerPointLoader, UnstructuredWordDocumentLoader\n)\n\nRAG_PERSIST_DIR = \"/kaggle/working/\"\nRAG_COLLECTION = \"rag_docs\"\n\ndef ingest_knowledge_base(file_path: str):\n    \"\"\"\n    Ingests a user-uploaded file (txt, pdf, csv, excel, ppt, docx).\n    \"\"\"\n    print(f\"ðŸ“‚ Ingesting file: {file_path}\")\n\n    # Pick loader based on file extension\n    ext = os.path.splitext(file_path)[1].lower()\n    if ext == \".txt\":\n        loader = TextLoader(file_path, encoding=\"utf-8\")\n    elif ext == \".pdf\":\n        loader = PyPDFLoader(file_path)\n    elif ext == \".csv\":\n        loader = CSVLoader(file_path)\n    elif ext in [\".xls\", \".xlsx\"]:\n        loader = UnstructuredExcelLoader(file_path)\n    elif ext in [\".ppt\", \".pptx\"]:\n        loader = UnstructuredPowerPointLoader(file_path)\n    elif ext in [\".doc\", \".docx\"]:\n        loader = UnstructuredWordDocumentLoader(file_path)\n    else:\n        raise ValueError(f\"âŒ Unsupported file type: {ext}\")\n\n    # Load documents\n    documents = loader.load()\n\n    # Split into chunks\n    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n    chunks = text_splitter.split_documents(documents)\n    \n    print(f\"âœ… File split into {len(chunks)} chunks.\")\n\n    # Update vector store\n    rag_db = Chroma.from_documents(\n        documents=chunks,\n        embedding=_embedding_fn,\n        persist_directory=RAG_PERSIST_DIR,\n        collection_name=RAG_COLLECTION\n    )\n\n    print(\"âœ… Knowledge base updated and saved.\")\n    return f\"File '{file_path}' ingested successfully!\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T18:24:10.099053Z","iopub.execute_input":"2025-09-14T18:24:10.099269Z","iopub.status.idle":"2025-09-14T18:24:10.106375Z","shell.execute_reply.started":"2025-09-14T18:24:10.099251Z","shell.execute_reply":"2025-09-14T18:24:10.105728Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# ------------------------\n# Memory helpers\n# ------------------------\ndef mem_add(text: str, kind: str = \"note\"):\n    \"\"\"Adds text to the vector store. Persistence is handled automatically.\"\"\"\n    _vectorstore.add_texts([f\"{kind}: {text}\"])\n    \n    # The erroneous .persist() line has been removed.\n    \n    # We can keep the debug print statement to see it working.\n    print(f\"ðŸ§  Memory Add Request Sent: '{kind}: {text[:60]}...'\")\n\ndef mem_recall(query: str, k: int = 3):\n    \"\"\"Recalls k most similar documents from the vector store.\"\"\"\n    docs = _vectorstore.similarity_search(query, k=k)\n    return [d.page_content for d in docs]\n\n# Place this with your other node functions\n\n# Replace your global DIRECT_ANSWER_SYS variable with this:\n\nDIRECT_ANSWER_SYS = \"\"\"\nYou are a helpful assistant that answers questions ONLY from the provided memory context.\nThe memory may contain structured facts in JSON format, like {\"entity\": \"user\", \"attribute\": \"name\", \"value\": \"haad\"}.\n\n- To answer the user's question, you MUST parse these JSON facts.\n- When asked 'what is my name' or about the 'user', look for facts where 'entity' is 'user'.\n- When asked 'what is your name' or about the 'agent', look for facts where 'entity' is 'agent'.\n- Use this information to answer precisely. Do not mention the JSON structure in your answer.\n\n- If the memory does NOT contain enough information to answer, you MUST respond with the exact phrase: 'NO_DIRECT_ANSWER' and nothing else.\n\"\"\"\n\ndef node_direct_answer(state: GraphState) -> GraphState:\n    \"\"\"Checks for a direct answer in memory before planning.\"\"\"\n    # âœ… CHANGE: Get the log and append actions\n    log = state.get(\"log\", [])\n    \n    mem_list = mem_recall(state.get(\"user_input\", \"\"), k=5)\n    facts = mem_recall(\"fact:\", k=5)\n    mem_list.extend(facts)\n    mem_list = list(set(mem_list))\n    mem_text = \"\\n\".join(mem_list) if mem_list else \"<none>\"\n\n    prompt = (DIRECT_ANSWER_SYS + \"\\nRelevant memory:\\n\" + mem_text + \"\\nUser input:\\n\" + state.get(\"user_input\", \"\"))\n    response = _llm.invoke(prompt).content.strip()\n\n    if \"NO_DIRECT_ANSWER\" in response:\n        log.append(\"ðŸ¤” Direct Answer: No direct answer found in memory. Proceeding to planner.\")\n        return {\"log\": log}\n    else:\n        log.append(\"âœ… Direct Answer: Found a direct answer in memory. Finalizing.\")\n        return {\"final\": response, \"log\": log}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T18:24:10.107193Z","iopub.execute_input":"2025-09-14T18:24:10.107439Z","iopub.status.idle":"2025-09-14T18:24:10.130839Z","shell.execute_reply.started":"2025-09-14T18:24:10.107412Z","shell.execute_reply":"2025-09-14T18:24:10.130160Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"# ------------------------\n# Safe JSON utilities\n# ------------------------\ndef extract_json_block(text: str) -> Optional[str]:\n    import re\n    match = re.search(r\"(\\{.*\\}|\\[.*\\])\", text, flags=re.S)\n    return match.group(1) if match else None\n\n\ndef safe_json_loads(text: str) -> Any:\n    try:\n        return json.loads(text)\n    except Exception:\n        block = extract_json_block(text)\n        if block:\n            try:\n                cleaned = block.replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n                return json.loads(cleaned)\n            except Exception as e:\n                return {\"error\": f\"json parse fail: {e}\", \"raw\": block}\n        return {\"error\": \"no json found\", \"raw\": text}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T18:24:10.131633Z","iopub.execute_input":"2025-09-14T18:24:10.131940Z","iopub.status.idle":"2025-09-14T18:24:10.151548Z","shell.execute_reply.started":"2025-09-14T18:24:10.131917Z","shell.execute_reply":"2025-09-14T18:24:10.150837Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"# ------------------------\n# Tools (web_search, calculator)\n# ------------------------\n\nfrom ddgs import DDGS\n\ndef tool_web_search(query: str, max_results: int = 5) -> Dict[str, Any]:\n    results: List[Dict[str, Any]] = []\n    try:\n        with DDGS() as ddgs:\n            for r in ddgs.text(query, max_results=max_results):\n                results.append({\n                    \"title\": r.get(\"title\"),\n                    \"href\": r.get(\"href\"),\n                    \"body\": r.get(\"body\"),\n                })\n    except Exception as e:\n        return {\"error\": f\"search_failed: {e}\"}\n    return {\"results\": results}\n\n\nclass _MathVisitor(ast.NodeVisitor):\n    allowed_nodes = (\n        ast.Expression, ast.BinOp, ast.UnaryOp, ast.Num, ast.Load,\n        ast.Add, ast.Sub, ast.Mult, ast.Div, ast.Mod, ast.Pow,\n        ast.USub, ast.UAdd, ast.FloorDiv\n    )\n    def visit(self, node):\n        if not isinstance(node, self.allowed_nodes):\n            raise ValueError(f\"disallowed expression: {type(node).__name__}\")\n        return super().visit(node)\n\n\ndef tool_calculator(expression: str) -> Dict[str, Any]:\n    try:\n        node = ast.parse(expression, mode=\"eval\")\n        _MathVisitor().visit(node)\n        value = eval(compile(node, \"<calc>\", \"eval\"), {\"__builtins__\": {}}, {})\n        return {\"ok\": True, \"result\": value}\n    except Exception as e:\n        return {\"ok\": False, \"error\": str(e)}\n\n\n# ===============================================================\n# âœ… Update tool_rag_search to always use the latest persisted DB\n# ===============================================================\ndef tool_rag_search(query: str) -> Dict[str, Any]:\n    try:\n        rag_db = Chroma(\n            persist_directory=RAG_PERSIST_DIR,\n            embedding_function=_embedding_fn,\n            collection_name=RAG_COLLECTION\n        )\n        docs = rag_db.similarity_search(query, k=3)\n        results_text = \"\\n---\\n\".join([d.page_content for d in docs])\n        return {\"results\": results_text or \"No relevant info found in the uploaded file.\"}\n    except Exception as e:\n        return {\"error\": f\"rag_search_failed: {e}\"}\n\n        \n\nTOOLS = {\n    \"web_search\": {\n        \"desc\": \"Search the web for general information, current events, or real-world people and places.\",\n        \"func\": lambda args: tool_web_search(args.get(\"query\", \"\"), int(args.get(\"max_results\", 3)))\n    },\n    \"calculator\": {\n        \"desc\": \"Evaluate arithmetic expressions.\",\n        \"func\": lambda args: tool_calculator(args.get(\"expression\", \"\"))\n    },\n    # âœ… UPDATE THIS DESCRIPTION\n    \"rag_search\": {\n        \"desc\": \"Use this tool to answer questions about the fantasy story 'The Lantern of Aetheria'. It contains specific knowledge about characters like Kael and Elara, and places like the city of Aetheria.\",\n        \"func\": lambda args: tool_rag_search(args.get(\"query\", \"\"))\n    }\n}\n\n# # This will automatically update the string passed to the Planner\n# TOOL_LIST_STR = \"\\n\".join([f\"- {name}: {meta['desc']}\" for name, meta in TOOLS.items()])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T18:24:10.152328Z","iopub.execute_input":"2025-09-14T18:24:10.152553Z","iopub.status.idle":"2025-09-14T18:24:10.171941Z","shell.execute_reply.started":"2025-09-14T18:24:10.152534Z","shell.execute_reply":"2025-09-14T18:24:10.171229Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"# ------------------------\n# Graph State\n# ------------------------\n# In your GraphState TypedDict definition\n\nclass GraphState(TypedDict, total=False):\n    user_input: str\n    memory_context: str\n    plan: List[Dict[str, Any]]\n    observations: List[Dict[str, Any]]\n    draft: str\n    feedback: str\n    reflections: int\n    final: str\n    # âœ… ADD THIS LINE: This will be our flight recorder.\n    log: List[str]\n\n\n# ------------------------\n# Node: Planner\n# ------------------------\n\n# âœ… NEW: A prompt specifically for understanding the user's true intent.\n# Replace your old INTENT_DISTILLER_PROMPT with this one\nINTENT_DISTILLER_PROMPT = \"\"\"\nYou are an intent distiller. Your job is to analyze the conversation and determine the user's real, actionable task.\n- If the user has provided a file, the primary task is to process that file using the instructions in the user's text.\n- If the user refers to a specific file (e.g., \"in summary.txt\"), separate the core question from the file reference.\n\nYour output should be a clear, actionable instruction for the Planner AI.\n\nExample 1:\nUser input: \"summarize the main points of the attached file\"\nFile Path: \"/path/to/doc.txt\"\nResult: \"The user has uploaded a file at /path/to/doc.txt and wants a summary. The first step is to add the file to the knowledge base, then search it for the main points.\"\n\nExample 2:\nUser input: \"whats the poem name in summary.txt\"\nFile Path: null\nResult: \"The user wants to know the name of the poem inside the file 'summary.txt'. The task is to search within that specific file for the poem's title.\"\n\nNow, distill the intent from the following:\n\"\"\"\n\n# Replace your old PLANNER_SYS prompt with this corrected version\n\n# âœ… THIS IS THE CORRECTED PROMPT. PLEASE REPLACE THE OLD ONE WITH THIS.\n\n# âœ… STEP 1: Replace your old PLANNER_SYS variable with this one.\n\nPLANNER_SYS = \"\"\"\nYou are the Planner. Your goal is to create a step-by-step plan to answer the user's task.\n**VERY IMPORTANT: Before creating a new plan, check 'Relevant memory'. If the answer is already there, your plan should be a single step to state the answer directly without using tools.**\n\nAvailable tools:\n{tool_list}\n\n**CRITICAL RULES for rag_search:**\n1.  When the user asks about a specific file (e.g., \"in summary.txt\"), you MUST use the `rag_search` tool with the `source_file` argument set to the filename (e.g., \"summary.txt\").\n2.  When using `source_file`, the `query` argument MUST be a question that represents the user's core goal. **DO NOT leave the query empty.** Reformulate the user's request into a proper question for the search.\n\n**Example of a good plan:**\nUser Task: \"The user wants to know the name of the poem inside the file 'summary.txt'.\"\nCorrect Plan:\n{\n  \"steps\": [\n    {\n      \"id\": 1,\n      \"thought\": \"I need to find the name of the poem inside 'summary.txt'. I will use rag_search and filter by the source file. I will also formulate a query to find the poem's name.\",\n      \"tool\": \"rag_search\",\n      \"args\": {\n        \"query\": \"What is the name of the poem?\",\n        \"source_file\": \"summary.txt\"\n      },\n      \"output_key\": \"poem_content\"\n    }\n  ]\n}\n\nReturn a STRICT JSON array named 'steps'.\n\"\"\"\n\n# âœ… STEP 2: Replace your entire old node_planner function with this one.\n\ndef node_planner(state: GraphState) -> GraphState:\n    log = state.get(\"log\", [])\n    user_input = state.get(\"user_input\", \"\")\n    file_path = state.get(\"file_path\")\n\n    # --- Intent Distiller Step ---\n    mem_list = mem_recall(user_input, k=4)\n    mem_text = \"\\n\".join(mem_list) if mem_list else \"<none>\"\n    file_info = f\"\\nFile Path: \\\"{file_path}\\\"\" if file_path else \"\\nFile Path: null\"\n\n    distiller_prompt = (\n        INTENT_DISTILLER_PROMPT\n        + \"\\nRelevant memory:\\n\" + mem_text\n        + \"\\nUser input:\\n\" + user_input\n        + file_info\n    )\n\n    distilled_task = _llm.invoke(distiller_prompt).content.strip()\n    log.append(f\"ðŸŽ¯ Planner: Distilled user intent to: '{distilled_task}'\")\n\n    # --- Planning Step ---\n    tool_list_str = \"\\n\".join([f\"- {name}: {meta['desc']}\" for name, meta in TOOLS.items()])\n    \n    # âœ… CHANGED: We now use the safe .replace() method instead of .format()\n    planner_prompt_template = PLANNER_SYS.replace(\"{tool_list}\", tool_list_str)\n\n    prompt = (\n        planner_prompt_template\n        + \"\\nRelevant memory (may be empty):\\n\" + mem_text\n        + \"\\nUser task:\\n\" + distilled_task\n        + \"\\nRespond with ONLY JSON in the format: {\\\"steps\\\":[...] }\\n\"\n    )\n    raw = _llm.invoke(prompt).content.strip()\n    parsed = safe_json_loads(raw)\n    steps = parsed.get(\"steps\") if isinstance(parsed, dict) and isinstance(parsed.get(\"steps\"), list) else []\n\n    log.append(f\"ðŸ“ Planner: Generated a plan with {len(steps)} step(s).\")\n    return {\"plan\": steps, \"log\": log}\n\n\n\n# ------------------------\n# Node: Executors\n# ------------------------\nEXECUTOR_SYS = \"\"\"\nYou are the Executor. Given the user's request, the plan, and tool observations,\nwrite a clear, helpful draft answer. If observations include search results, cite them inline textually (titles/domains), but do not fabricate links.\nIf no tools were used, answer from general knowledge + memory context. Keep it concise unless the user asked for depth.\n\"\"\"\n\n\ndef _run_tools(steps: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n    observations: List[Dict[str, Any]] = []\n    for step in steps:\n        tool_name = step.get(\"tool\")\n        args = step.get(\"args\", {}) or {}\n        if tool_name and tool_name in TOOLS:\n            try:\n                obs = TOOLS[tool_name][\"func\"](args)\n            except Exception as e:\n                obs = {\"error\": f\"tool_error: {e}\"}\n        else:\n            obs = {\"note\": \"no_tool\"}\n        observations.append({\n            \"id\": step.get(\"id\"),\n            \"tool\": tool_name,\n            \"args\": args,\n            \"observation\": obs,\n        })\n    return observations\n\n\ndef node_executor(state: GraphState) -> GraphState:\n    \"\"\"Runs tools and generates a draft answer.\"\"\"\n    # âœ… CHANGE: Get the log and append actions\n    log = state.get(\"log\", [])\n    plan = state.get(\"plan\", [])\n    \n    tool_steps = [step for step in plan if step.get(\"tool\")]\n    if tool_steps:\n        tools_str = \", \".join([step['tool'] for step in tool_steps])\n        log.append(f\"ðŸ› ï¸ Executor: Running tool(s): {tools_str}\")\n    else:\n        log.append(\"ðŸ§  Executor: No tools to run. Answering from general knowledge.\")\n\n    observations = []\n    for step in plan:\n        tool_name = step.get(\"tool\")\n        args = step.get(\"args\", {}) or {}\n        if tool_name and tool_name in TOOLS:\n            obs = TOOLS[tool_name][\"func\"](args)\n        else:\n            obs = {\"note\": \"no_tool\"}\n        observations.append({\"id\": step.get(\"id\"), \"tool\": tool_name, \"args\": args, \"observation\": obs})\n\n    context_blob = json.dumps({\"plan\": plan, \"observations\": observations, \"user_input\": state.get(\"user_input\", \"\")}, ensure_ascii=False)\n    draft_prompt = \"You are the Executor... \\nContext JSON:\\n\" + context_blob + \"\\nDraft the answer now.\"\n    draft = _llm.invoke(draft_prompt).content.strip()\n    \n    return {\"observations\": observations, \"draft\": draft, \"log\": log}\n\n\n# ------------------------\n# Node: Verifier (reflection loop)\n# ------------------------\nVERIFIER_SYS = \"\"\"\nYou are the Verifier. Check the draft for factuality, clarity, safety, and task completion.\nReturn ONLY JSON: {\"approved\": bool, \"feedback\": \"...\", \"final\": \"...\"}\n- If approved: polish the draft lightly and place in 'final'.\n- If NOT approved: explain issues in 'feedback' and leave 'final' empty.\nBe conservative; prefer one more revision if unsure.\n\"\"\"\n\n\ndef node_verifier(state: GraphState) -> GraphState:\n    \"\"\"Verifies the draft answer.\"\"\"\n    # âœ… CHANGE: Get the log and append actions\n    log = state.get(\"log\", [])\n    \n    prompt = (VERIFIER_SYS + \"\\nUser input:\\n\" + state.get(\"user_input\", \"\") + \"\\nDraft:\\n\" + (state.get(\"draft\", \"\") or \"\") + \"\\nObservations (for verification):\\n\" + json.dumps(state.get(\"observations\", []), ensure_ascii=False))\n    raw = _llm.invoke(prompt).content.strip()\n    parsed = safe_json_loads(raw)\n    \n    if isinstance(parsed, dict) and parsed.get(\"approved\") and parsed.get(\"final\"):\n        log.append(\"âœ… Verifier: Draft approved.\")\n        return {\"final\": parsed.get(\"final\"), \"log\": log}\n\n    fb = parsed.get(\"feedback\", \"\") if isinstance(parsed, dict) else \"needs another pass\"\n    log.append(f\"âŒ Verifier: Draft not approved. Feedback: '{fb[:50]}...'. Replanning.\")\n    mem_add(f\"verifier_feedback: {fb}\", kind=\"feedback\")\n    return {\"feedback\": fb, \"reflections\": (state.get(\"reflections\", 0) + 1), \"log\": log}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T18:24:10.174037Z","iopub.execute_input":"2025-09-14T18:24:10.174331Z","iopub.status.idle":"2025-09-14T18:24:10.193850Z","shell.execute_reply.started":"2025-09-14T18:24:10.174315Z","shell.execute_reply":"2025-09-14T18:24:10.193150Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# ------------------------\n# Node: Memory Updater (end)\n# ------------------------\n\ndef node_memory_update(state: GraphState) -> GraphState:\n    \"\"\"Saves the conversation and extracts structured facts to memory.\"\"\"\n    log = state.get(\"log\", [])\n    log.append(\"ðŸ’¾ Memory: Saving final answer and user query to long-term memory.\")\n    \n    ui = state.get(\"user_input\", \"\")\n    final = state.get(\"final\", \"\")\n    if ui: mem_add(ui, kind=\"user\")\n    if final: mem_add(final, kind=\"agent\")\n\n    # âœ… CHANGE: Upgraded to structured JSON fact extraction\n    # This block replaces the old, simple fact extraction.\n    low = ui.lower()\n    \n    # For the user's name\n    if \"my name is\" in low:\n        name = low.split(\"my name is\", 1)[-1].strip().strip(\".?! \")\n        if name:\n            fact_json = json.dumps({\"entity\": \"user\", \"attribute\": \"name\", \"value\": name})\n            mem_add(fact_json, kind=\"fact\")\n            \n    # For the agent's name\n    if \"your name is\" in low or \"ur name is\" in low:\n        name = low.split(\" is \", 1)[-1].strip().strip(\".?! \")\n        if name:\n            fact_json = json.dumps({\"entity\": \"agent\", \"attribute\": \"name\", \"value\": name})\n            mem_add(fact_json, kind=\"fact\")\n\n    # For other facts, like a brother's name\n    if \"my brother name is\" in low:\n        name = low.split(\"my brother name is\", 1)[-1].strip().strip(\".?! \")\n        if name:\n            fact_json = json.dumps({\"entity\": \"user's brother\", \"attribute\": \"name\", \"value\": name})\n            mem_add(fact_json, kind=\"fact\")\n\n    return {\"log\": log}\n\ndef finalizer(state: GraphState) -> GraphState:\n    final_answer = state.get(\"draft\") or \"[Agent had no result]\"\n    return {**state, \"final\": final_answer}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T18:24:10.194652Z","iopub.execute_input":"2025-09-14T18:24:10.195318Z","iopub.status.idle":"2025-09-14T18:24:10.212934Z","shell.execute_reply.started":"2025-09-14T18:24:10.195293Z","shell.execute_reply":"2025-09-14T18:24:10.212341Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"# ------------------------\n# Graph assembly\n# ------------------------\n\ndef run_agent_once(user_input: str) -> Dict[str, Any]:\n    global _vectorstore\n    _vectorstore = Chroma(\n        collection_name=MEM_COLLECTION,\n        embedding_function=_embedding_fn,\n        persist_directory=PERSIST_DIR\n    )\n    graph = build_graph()\n    # âœ… CHANGE: Initialize the log in the state\n    state: GraphState = {\"user_input\": user_input, \"reflections\": 0, \"log\": []}\n    result = graph.invoke(state)\n    return result\n\n    \n# Place this with your _should_reflect function\n# âœ… THIS IS THE MISSING FUNCTION\ndef _should_reflect(state: GraphState) -> str:\n    if state.get(\"final\"):\n        return \"approved\"\n    if int(state.get(\"reflections\", 0)) >= MAX_REFLECTIONS:\n        return \"give_up\"\n    return \"replan\"\n\ndef should_plan_or_finish(state: GraphState) -> str:\n    \"\"\"Decides whether to plan or end the process.\"\"\"\n    if state.get(\"final\"):\n        # A direct answer was found by the previous node.\n        return \"finish\"\n    else:\n        # No direct answer, so we must proceed to planning.\n        return \"plan\"\n        \n# Replace your build_graph function with this final version\n\ndef build_graph():\n    workflow = StateGraph(GraphState)\n\n    # Add the new node\n    workflow.add_node(\"direct_answer\", node_direct_answer)\n    \n    workflow.add_node(\"planner\", node_planner)\n    workflow.add_node(\"executor\", node_executor)\n    workflow.add_node(\"verifier\", node_verifier)\n    workflow.add_node(\"finalizer\", finalizer)\n    workflow.add_node(\"memory\", node_memory_update)\n\n    # The entry point is now our direct_answer node\n    workflow.set_entry_point(\"direct_answer\")\n\n    # Add the new conditional edge\n    workflow.add_conditional_edges(\n        \"direct_answer\",\n        should_plan_or_finish,\n        {\n            \"finish\": \"memory\", # If we have an answer, just save the convo and end.\n            \"plan\": \"planner\"   # If no answer, start the main planning loop.\n        }\n    )\n    \n    # This is the original agent loop\n    workflow.add_edge(\"planner\", \"executor\")\n    workflow.add_edge(\"executor\", \"verifier\")\n    workflow.add_conditional_edges(\n        \"verifier\",\n        _should_reflect,\n        {\n            \"replan\": \"planner\",\n            \"approved\": \"memory\",\n            \"give_up\": \"finalizer\"\n        }\n    )\n    workflow.add_edge(\"finalizer\", \"memory\")\n    workflow.add_edge(\"memory\", END)\n\n    return workflow.compile()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T18:24:10.213620Z","iopub.execute_input":"2025-09-14T18:24:10.213852Z","iopub.status.idle":"2025-09-14T18:24:10.232614Z","shell.execute_reply.started":"2025-09-14T18:24:10.213832Z","shell.execute_reply":"2025-09-14T18:24:10.232029Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"# ------------------------\n# Public API\n# ------------------------\ndef run_agent_once(user_input: str) -> Dict[str, Any]:\n    global _vectorstore\n    \n    # âœ… THE FIX: Create a new Chroma instance, loading the latest data from disk.\n    # Assign it to the global variable so all your node functions can use it.\n    _vectorstore = Chroma(\n        collection_name=MEM_COLLECTION,\n        embedding_function=_embedding_fn,\n        persist_directory=PERSIST_DIR\n    )\n    \n    graph = build_graph()\n    state: GraphState = {\"user_input\": user_input, \"reflections\": 0}\n    result = graph.invoke(state)\n    return result\n\n\nif __name__ == \"__main__\":\n    if not os.environ.get(\"GROQ_API_KEY\"):\n        print(\"[WARN] GROQ_API_KEY is not set. Set it before running for LLM calls.\")\n    demo_q = \"Give me 3 bullet points on why AI agents are useful for students.\"\n    out = run_agent_once(demo_q)\n    print(\"\\n=== FINAL ANSWER ===\\n\", out.get(\"final\"))\n    print(\"\\n--- Debug state keys ---\\n\", list(out.keys()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T18:24:10.233258Z","iopub.execute_input":"2025-09-14T18:24:10.233487Z","iopub.status.idle":"2025-09-14T18:24:11.673562Z","shell.execute_reply.started":"2025-09-14T18:24:10.233466Z","shell.execute_reply":"2025-09-14T18:24:11.672714Z"}},"outputs":[{"name":"stdout","text":"ðŸ§  Memory Add Request Sent: 'user: Give me 3 bullet points on why AI agents are useful for stud...'\nðŸ§  Memory Add Request Sent: 'agent: <think>\nOkay, the user is asking \"who is Sahil Mulla\" after ...'\n\n=== FINAL ANSWER ===\n <think>\nOkay, the user is asking \"who is Sahil Mulla\" after I provided bullet points on AI agents for students. Let me check the memory context.\n\nLooking back, there's a memory entry about Sahil Mulla related to a Network Security Monitoring System project from 2022â€“2023. The details include his work on session tracking, user management, key logging, and a secure workspace. Also, his contact info: phone +91 9152754549 and email sahilmulla9152@gmail.com. There's a feedback note mentioning a possible name discrepancy with 'Sahil M' in a podcast URL, but it's unclear if they're the same person.\n\nThe user might be asking about the Sahil Mulla mentioned in the document. Since the memory has structured facts about him, I should use that. The answer should summarize his project and note the name discrepancy. I need to avoid mentioning JSON and stick to the provided info. Also, check if there's enough info to answer directly. Yes, the memory has enough details to provide a concise answer without uncertainty.\n</think>\n\nSahil Mulla is associated with the development of a **Network Security Monitoring System** (2022â€“2023), which includes features like session tracking, user management, key logging, and a dedicated workspace for enhanced data security. Key details from the uploaded document include:\n\n- **Project Focus**: The system provides insights into user behavior and activity, ensuring efficient monitoring and security.\n- **Experience**: Worked on real-life web applications, gaining expertise in **front-end and back-end development**.\n- **Contact Information**: \n  - Phone: +91 9152754549\n  - Email: sahilmulla9152@gmail.com\n\nThe document does not provide additional personal details beyond his professional work on the security system and IT solutions.\n\n--- Debug state keys ---\n ['user_input', 'reflections', 'final', 'log']\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"# =======================\n# Chat Loop for Agent\n# =======================\ndef chat_loop():\n    print(\"ðŸ¤– Agent ready! Type 'exit' to quit.\\n\")\n    while True:\n        user_input = input(\"You: \")\n        if user_input.strip().lower() in [\"exit\", \"quit\", \"q\"]:\n            print(\"ðŸ‘‹ Goodbye!\")\n            break\n\n        result = run_agent_once(user_input)\n        \n        # âœ… CHANGE: Added the block to print the log\n        print(\"\\n--- ðŸ•µï¸ Agent's Thought Process ---\")\n        log = result.get(\"log\", [])\n        for step in log:\n            print(f\"âž¡ï¸ {step}\")\n        print(\"---------------------------------\")\n        \n        print(\"\\nAgent:\\n\", result.get(\"final\", \"[No final output]\"))\n\n        recalls = mem_recall(user_input, k=2)\n        if recalls:\n            print(\"\\nðŸ’¾ Memory recall:\\n\", \"\\n\".join(recalls))\n\n# === Run chat ===\nif __name__ == \"__main__\":\n    chat_loop()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T18:24:11.674396Z","iopub.execute_input":"2025-09-14T18:24:11.675143Z","iopub.status.idle":"2025-09-14T18:25:01.180553Z","shell.execute_reply.started":"2025-09-14T18:24:11.675122Z","shell.execute_reply":"2025-09-14T18:25:01.179911Z"}},"outputs":[{"name":"stdout","text":"ðŸ¤– Agent ready! Type 'exit' to quit.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  quit\n"},{"name":"stdout","text":"ðŸ‘‹ Goodbye!\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"# The text of your story\nknowledge_base_text = \"\"\"\n\"Moonlit Night\"\n\nThe stars shine bright in the midnight sky\nA gentle breeze whispers by\nThe world is hushed, in quiet sleep\nAs the moon's soft light begins to creep\n\nThe shadows dance upon the wall\nA midnight serenade, for one and all\nThe moon's sweet beams, illuminate the night\nA peaceful scene, a wondrous sight.\n\"\"\"\n\n# The Fix: Use a relative path to save the file in /kaggle/working/\nfile_path = \"Moonlit.txt\"\nwith open(file_path, \"w\") as f:\n    f.write(knowledge_base_text)\n\nprint(f\"âœ… '{file_path}' created successfully in /kaggle/working/.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T18:25:01.181791Z","iopub.execute_input":"2025-09-14T18:25:01.182042Z","iopub.status.idle":"2025-09-14T18:25:01.186947Z","shell.execute_reply.started":"2025-09-14T18:25:01.182015Z","shell.execute_reply":"2025-09-14T18:25:01.186428Z"}},"outputs":[{"name":"stdout","text":"âœ… 'Moonlit.txt' created successfully in /kaggle/working/.\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"import gradio as gr\nimport markdown\n\n# Function to handle file ingestion\nimport os\nimport traceback\n\ndef upload_file(files):\n    # This function will now receive a list of files\n    if not files:\n        return \"âš ï¸ Please upload at least one file.\"\n\n    results = []\n    # Loop through each file in the list\n    for file in files:\n        file_path = file.name\n        try:\n            # Call the ingestion function for each file\n            status = ingest_knowledge_base(file_path)\n            results.append(status)\n        except Exception as e:\n            error_msg = \"\".join(traceback.format_exception_only(type(e), e))\n            print(\"âŒ Ingestion failed:\", error_msg)\n            results.append(f\"âŒ Error ingesting {os.path.basename(file_path)}: {error_msg}\")\n    \n    # Return a single string with the status of all files\n    return \"\\n\".join(results)\n\n\n\n# Function for chat\ndef run_agent_for_ui(user_input, history):\n    print(f\"Received input: {user_input}\")\n    result = run_agent_once(user_input)\n\n    # Format output\n    log_steps = result.get(\"log\", [])\n    final_answer = result.get(\"final\", \"I'm sorry, I encountered an error.\")\n    \n    log_html = \"<details><summary>ðŸ•µï¸ Click to see Agent's Thought Process</summary><ul>\"\n    for step in log_steps:\n        safe_step = markdown.markdown(step.replace(\"\\n\", \"<br>\"))\n        log_html += f\"<li>{safe_step}</li>\"\n    log_html += \"</ul></details>\"\n\n    return f\"{final_answer}\\n\\n{log_html}\"\n\nprint(\"Launching Gradio UI...\")\n\n# Build UI with file upload + chat\nwith gr.Blocks() as demo:\n    gr.Markdown(\"## ðŸ“˜ General AI Agent with Custom Knowledge Base\")\n    \n    with gr.Tab(\"ðŸ“‚ Upload File\"):\n        file_input = gr.File(label=\"Upload documents\", file_types=[\".txt\", \".pdf\", \".csv\", \".xlsx\", \".pptx\"], file_count=\"multiple\")\n        upload_output = gr.Textbox(label=\"Ingestion Status\")\n        file_input.change(upload_file, inputs=file_input, outputs=upload_output)\n    \n    with gr.Tab(\"ðŸ’¬ Chat with Agent\"):\n        gr.ChatInterface(\n            fn=run_agent_for_ui,\n            title=\"Chat with AI Agent\",\n            description=\"You can now query on your uploaded file.\"\n        )\n\ndemo.launch(share=True, debug=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T18:38:56.512092Z","iopub.execute_input":"2025-09-14T18:38:56.512436Z","iopub.status.idle":"2025-09-14T18:40:35.190119Z","shell.execute_reply.started":"2025-09-14T18:38:56.512403Z","shell.execute_reply":"2025-09-14T18:40:35.189497Z"}},"outputs":[{"name":"stdout","text":"Launching Gradio UI...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/gradio/chat_interface.py:339: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n  self.chatbot = Chatbot(\n","output_type":"stream"},{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7861\n* Running on public URL: https://81a9c0827d7643b215.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://81a9c0827d7643b215.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"name":"stdout","text":"ðŸ“‚ Ingesting file: /tmp/gradio/2e753e19037bfac12b4cfef9d06ded1c984bd699c2d97669576e097961227428/2.pdf\nâœ… File split into 154 chunks.\nâœ… Knowledge base updated and saved.\nðŸ“‚ Ingesting file: /tmp/gradio/2e753e19037bfac12b4cfef9d06ded1c984bd699c2d97669576e097961227428/2.pdf\nâœ… File split into 154 chunks.\nâœ… Knowledge base updated and saved.\nðŸ“‚ Ingesting file: /tmp/gradio/7cd182f8f41b1b58b775ce1d685121caf257ad283e9e64b25b6369f3e9d49278/asjjsjsjs 1.txt\nâœ… File split into 1 chunks.\nâœ… Knowledge base updated and saved.\nðŸ“‚ Ingesting file: /tmp/gradio/7cd182f8f41b1b58b775ce1d685121caf257ad283e9e64b25b6369f3e9d49278/asjjsjsjs.txt\nâœ… File split into 1 chunks.\nâœ… Knowledge base updated and saved.\nðŸ“‚ Ingesting file: /tmp/gradio/2e753e19037bfac12b4cfef9d06ded1c984bd699c2d97669576e097961227428/2.pdf\nâœ… File split into 154 chunks.\nâœ… Knowledge base updated and saved.\nðŸ“‚ Ingesting file: /tmp/gradio/7cd182f8f41b1b58b775ce1d685121caf257ad283e9e64b25b6369f3e9d49278/asjjsjsjs 1.txt\nâœ… File split into 1 chunks.\nâœ… Knowledge base updated and saved.\nðŸ“‚ Ingesting file: /tmp/gradio/7cd182f8f41b1b58b775ce1d685121caf257ad283e9e64b25b6369f3e9d49278/asjjsjsjs.txt\nâœ… File split into 1 chunks.\nâœ… Knowledge base updated and saved.\nðŸ“‚ Ingesting file: /tmp/gradio/b793d18d4dca5ed64a46e9dc0fb59e2578c81abd392cec928bc59d7e73a917b7/1-s2.0-S1365160924000923-main.pdf\nâœ… File split into 154 chunks.\nâœ… Knowledge base updated and saved.\nKeyboard interruption in main thread... closing server.\nKilling tunnel 127.0.0.1:7861 <> https://81a9c0827d7643b215.gradio.live\n","output_type":"stream"},{"execution_count":53,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}],"execution_count":53}]}